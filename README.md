GREEN (35-50%):
The 35% lower bound is established through statistical significance studies demonstrating consistent risk separation at this level. Historical portfolio performance data validates that 35% separation delivers reliable default prediction with false positive/negative rates falling below 25%. The 50% upper bound stems from mathematical and empirical analysis showing that separation beyond this point typically indicates model overfitting rather than genuine discriminatory power.
AMBER (20-35%):
The 20% lower boundary represents the minimum statistically significant separation from random classification. At this level, models demonstrate marginally acceptable discrimination power but operate sub-optimally. The 35% upper limit marks the transition point where model performance becomes statistically robust based on industry-wide performance studies and risk-return optimization analysis.
RED (<20%):
This threshold derives from statistical power analysis demonstrating that separation below 20% produces unreliable risk discrimination. Regulatory frameworks and empirical studies consistently show that models operating below this threshold generate unsustainable error rates and inadequate risk differentiation.
PSI (Population Stability Index) Thresholds:
GREEN (<0.1):
This threshold derives from chi-square distribution properties and statistical significance levels. Empirical validation across multiple institutions demonstrates that population stability remains intact below 0.1, maintaining model predictive power and fundamental assumptions.
AMBER (0.1-0.2):
This range emerges from statistical analysis of population drift significance. The boundaries reflect the point where variable distributions begin showing material deviation while still maintaining partial model effectiveness. Historical analysis demonstrates that this range provides adequate warning time for model maintenance.
RED (>0.2):
The 0.2 threshold represents the point where statistical tests show fundamental breaks in population characteristics. Beyond this level, error rates increase exponentially and model assumptions become invalidated based on extensive back-testing studies.
